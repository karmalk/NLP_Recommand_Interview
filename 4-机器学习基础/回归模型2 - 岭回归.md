# 岭回归 

## 简介

岭回归本质上是 **线性回归 + L2 正则化**。

## 岭回归与线性回归

线性回归中通过正规方程得到的 w 的估计：
$$
\hat{w} = (X^TX)^{-1}X^Ty
$$
但是，当我们有 N 个样本，每个样本有 $x_i \in R^p$， 当 N < p 时， $X^TX$ 不可逆， 无法通过正规方程计算，容易造成过拟合。

岭回归通过在矩阵 $X^TX$ 上加一个 $\lambda I$ 来使得矩阵可逆， 此时的 w 的估计：
$$
\hat{w} = (X^TX + \lambda I)^{-1}X^Ty
$$
而岭回归本质上是对 $L(w)$  进行 L2 正则化， 此时的 $J(w)$ 表示为：
$$
\begin{align}
J(w) &= \sum_{i=1}^N ||w^Tx_i - y_i ||^2 + \lambda w^Tw \\
&= (w^TX^T - Y^T)(Xw - Y) + \lambda w^Tw \\
&= w^TX^TXw - 2w^TX^TY  + Y^TY + \lambda w^Tw \\
&= w^T(X^TX + \lambda I)w - 2w^TX^TY + Y^TY
\end{align}
$$
那么对 $w$ 的极大似然估计有：
$$
\hat{w} = argmax \, J(w) \\
\frac{\delta J(w)}{\delta w} = 2(X^TX + \lambda I)w - 2 X^TY = 0
$$
那么我们就解得：
$$
\hat{w} = (X^TX + \lambda I)^{-1}X^Ty
$$
因此说， 岭回归本质上是 **线性回归 + L2 正则化**， 从而达到抑制过拟合的效果。

---

## QA

### 1. 什么时候使用岭回归 ？

如果样本数据过少导致线性回归拟合较差，则考虑采用岭回归。如何输入特征的维度很高,而且是稀疏线性关系的话， 岭回归就不太合适,考虑使用Lasso回归。


# 朴素贝叶斯
tags: machine-learning

---

[TOC]

## 1. 基本概念

### 1. 条件概率

$$
P(X|Y) =  \frac{P(X,Y)}{P(Y)}
$$

- $P(X|Y)$含义： 表示 y 发生的条件下 x 发生的概率。

### 2. 先验概率

- 含义： **表示事件发生前的预判概率。**这个可以是基于历史数据统计，也可以由背景常识得出，也可以是主观观点得出。一般都是单独事件发生的概率，如 P(A)

### 3. 后验概率

- 基于先验概率求得的**反向条件概率**，形式上与条件概率相同（若 `P(X|Y)` 为正向，则 `P(Y|X)` 为反向）

## 2. 贝叶斯公式

贝叶斯公式如下：
$$
P(Y|X) = \frac{P(X|Y) P(Y)}{P(X)}  \\
$$
> - P(Y) 叫做**先验概率**，意思是事件X发生之前，我们对事件Y发生的一个概率的判断
> - P(Y|X) 叫做**后验概率**，意思是时间X发生之后，我们对事件Y发生的一个概率的重新评估
> - P(Y,X) 叫做**联合概率**， 意思是事件X与事件Y同时发生的概率。

## 3. 条件独立假设

$$
P(x|c) = p(x_1, x_2,  \cdots x_n | c) = \prod_{i=1}^Np(x_i | c)
$$

朴素贝叶斯采用条件独立假设的动机在于： **简化运算。**

## 4. 从机器学习视角理解朴素贝叶斯

**朴素贝叶斯 = 贝叶斯方法 + 条件独立假设。**

在机器学习中，我们可以将 X 理解为“具有某特征”， 而 Y 理解为“类别标签”，于是有：
$$
P("属于某类“ \, \, | \, \, "具有某特征" ) = \frac{P("具有某特征" | "属于某类") P("属于某类")}{P("具有某特征" )}
$$

而贝叶斯派目的是要对 Y 进行优化：
$$
\begin{align}
Y_{MAP} &= argmax_y P(Y|X)  \\
&= argmax_y \frac{P(X,Y)}{P(X)} \\
&= argmax_y P(Y) P(X|Y)
\end{align}
$$

## 朴素贝叶斯中的三种模型

### 1.  多项式模型

多项式模型适用于离散特征情况，在文本领域应用广泛， 其基本思想是：**我们将重复的词语视为其出现多次**。

### 2. 高斯模型

https://blog.csdn.net/u012162613/article/details/48323777

http://www.letiantian.me/2014-10-12-three-models-of-naive-nayes/

高斯模型适合**连续特征情况**， 我们先给出高斯公式：
$$
P(x_{i}|y_{k}) = \frac{1}{\sqrt{2\pi\sigma_{y_{k}}^{2}}}exp( -\frac{(x_{i}-\mu_{y_{k}})^2}  {2\sigma_{y_{k}}^{2}}   )
$$


### 3. 伯努利模型

> 伯努利模型适用于离散特征情况，它将重复的词语都视为只出现一次。
> $$
> P( " 代开“， ”发票“， ”发票“， ”我“ | S) = P("代开" | S)   P( ”发票“ | S) P("我" | S)
> $$
> 我们看到，”发票“出现了两次，但是我们只将其算作一次。

---

## QA

### 1. 朴素贝叶斯为何朴素？

朴素贝叶斯的朴素性体现在该算法基于一个简单的假设： **所有的变量都是相互独立的**，用贝叶斯公式表达如下：
$$
P(Y|X_1, X_2) = \frac{P(X_1|Y) P(X_2|Y) P(Y)}{P(X_1)P(X_2)}
$$
**而在很多情况下，所有变量几乎不可能满足两两之间的条件。**

### 2. 朴素贝叶斯分类中某个类别的概率为0怎么办？

**问题：** 如下，A1,A2,A3是三个特征，Y是分类结果。

|  A1  |  A2  |  A3  |  Y   |
| :--: | :--: | :--: | :--: |
|  1   |  1   |  0   |  1   |
|  0   |  1   |  1   |  1   |
|  1   |  0   |  1   |  0   |
|  0   |  1   |  0   |  0   |
|  0   |  0   |  1   |  0   |

```
P(Y=0) = 3/5
P(Y=1) = 2/5
P(Y=0|A1=1,A2=0,A3=0) = 3/5 * 1/3 * 2/3 * 1/3 = 2/45
P(Y=1|A1=1,A2=0,A3=0) = 2/5 * 1/2 * 1/4 * 1/2 = 1/40
```

答案是 **拉普拉斯平滑**。

### 3. 朴素贝叶斯的要求是什么？

- 贝叶斯定理
- 特征条件独立假设

### 4. 朴素贝叶斯的优缺点？

- 优点： 对小规模数据表现很好，适合多分类任务，适合增量式训练。
- 缺点：对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）。

### 5. 朴素贝叶斯与 LR 区别？

-  朴素贝叶斯是生成模型，根据已有样本进行贝叶斯估计学习出先验概率 P(Y) 和条件概率 P(X|Y)，进而求出联合分布概率 P(XY)，最后利用贝叶斯定理求解P(Y|X)， 而LR是判别模型，根据极大化对数似然函数直接求出条件概率 P(Y|X)
-  朴素贝叶斯是基于很强的**条件独立假设**（在已知分类Y的条件下，各个特征变量取值是相互独立的），而 LR 则对此没有要求
-  朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。




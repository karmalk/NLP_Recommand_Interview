# 基础理论 - 概率图模型

## 1，简单介绍下**概率图模型**

对于一个实际问题，我们希望能够挖掘隐含在数据中的知识。概率图模型构建了这样一幅图，用观测结点表示观测到的数据，用隐藏节点表示潜在的知识，用边来描述**知识**和**数据**的相互关系，最后基于这样的关系图获得一个概率分布，便是概率图模型。

概率图中的节点分为**隐含节点**和**观测节点**，边分为有向边和无向边。从概率论的角度，节点对应于随机变量，边对应于随机变量的依赖或者相关关系，其中有向边表示单向依赖，无向边表示相互依赖。概率图模型分为**贝叶斯网络**和**马尔可夫网络**，贝叶斯网络可以用一个**有向图结构**表示，马尔可夫网络可以表示成一个**无向图的网络结构**，概率图模型主要包括**朴素贝叶斯**，**最大熵模型**，**隐马尔可夫模型**，**条件随机场**，**主题模型**(pLSA,LDA(尹狄利克雷))。

## 2，最大熵模型

## 3，隐马尔科夫模型

 隐马尔可夫模型是关于时序的**概率模型**，是可用于标注问题的统计学习模型，描述由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个**状态**生成一个**观测**而产生**观测随机序列**的过程。

隐马尔科夫模型由**初始状态概率向量**$\pi$,**状态转移概率矩阵**A和**观测概率矩阵**B决定，隐马尔可夫模型可以写成$\lambda (A,B,\pi)$

隐马尔科夫模型是生成模型，表示状态序列和观测序列的联合分布，但是状态序列是隐藏的，不可观测的。

隐马尔科夫模型可以用于标注，这是状态对应着标记，标注问题是给定**观测序列预测**其对应的**标记序列**。

**三个问题**：

- **概率计算问题**：给定模型$\lambda = (A,B,\pi)$,和观测序列$O=(o_!,o_2,...,o_n)$,计算在模型$\lambda$下观测序列O出现的概率$P(O|\lambda)$,.**前向-后向算法**是通过递推地计算前向-后向概率可以高效地进行隐马尔可夫模型的概率计算。
- **学习问题**
  - 已知观测序列$O = (o_1,o_2,...,o_T)$,估计模型$\lambda = (A,B,\pi)$参数，使得在该模型下观测序列概率$P(O|\lambda)$最大。即用极大似然估计的方法估计参数。**Baum-Welch(BW)**算法，也就是EM算法可以高效地对隐马尔可夫模型进行训练，是一种**非监督学习算法**。
- **预测问题**
  - 已知模型$\lambda = (A,B,\pi)$和观测序列$O = (o_1,o_2,...,o_T)$,求对给定观测序列条件概率P(I|O)最大的状态序列$I = (i_1,i_2,i_3,...,i_T)$。**维特比**算法应用动态规划高效地求解最优路径，即概率最大地状态序列。


# 模型 - KNN

---

[TOC]

## 简介

KNN算法是分类算法的一种，也属于监督学习算法，其基本思想为：

- 当输入一个新的样本时，将新数据的每个特征与样本集中每个样本数据的特征进行比较。

- 从样本集中选取最**相近**的 K 个样本，然后依据某种决策原则（少数服从多数）来判定这个新样本的 label。

在KNN算法中，有三个主要要素：距离度量，K 的取值，分类决策规则。

## 算法步骤

- 计算新数据与数据集中所有样本之间的距离， 距离度量公式可以选择多种，如欧式距离，曼哈顿距离等。可以参见：[基础理论 - 距离度量方法](./基础理论 - 距离度量方法.md)
- 按照距离，将样本按照距离值进行排序

- 选取与当前数据距离最小的 K 个点。
- 返回这 K 个点的 label， 依据某种决策原则来判定这个新数据的 label 。

## K 的选择

- 如果 K 较小，预测结果会对邻近的点十分敏感，如果邻近点恰好是噪声，则很容易预测错误。 换个角度说说， **K的减小意味着模型变得复杂，容易发生过拟合。**
- 如果K 较大， 此时不相似的样本也会对预测产生作用，使得预测发生错误。换个角度说，**K的增大意味着模型变得简单，容易发生欠拟合。**



---

## QA

### 1. KNN 中为何采用欧式距离而不采用曼哈顿距离？

我们不用曼哈顿距离，因为它只计算水平或垂直距离，有维度的限制。另一方面，欧式距离可用于任何空间的距离计算问题。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。例如：想象一下国际象棋棋盘，象或车所做的移动是由曼哈顿距离计算的，因为它们是在各自的水平和垂直方向的运动。

### 2. 


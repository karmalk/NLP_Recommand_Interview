# 交叉科技笔试题

![TIM截图20200229145449](D:\算法岗面试学习之路\NLPer-Interview-master\10算法面经\image\TIM截图20200229145449.png)

- 一个国王要求从他的国家的10个地区各征收1000枚金币的税。
  每个地区的税务员都会在年底时把他要的那袋金币带来。
  一个线人告诉国王，有一个收税员作弊，给的硬币比标准硬币轻10%，但他不知道哪个收税员作弊。国王知道每枚硬币的重量应该正好是一盎司。国王怎样才能通过使用称重设备准确地一次识别出骗子呢?
- 你站在一个半径为r的圆形场的中心，场周围有一个低矮的铁丝网。
  附在铁丝栅栏上的是一只拉果尖牙的饿狗，它喜欢吃它能抓到的任何人类。你可以以速度v运行。
  不幸的是，这只狗可以跑四倍的速度，在4v。如果你试图逃离这片田野，这条狗会尽力抓住你。
  在不喂狗的情况下，你跑步的策略是什么?

![TIM截图20200229150045](D:\算法岗面试学习之路\NLPer-Interview-master\10算法面经\image\TIM截图20200229150045.png)

**1，怎么解释软间隔SVM为一种惩罚方法。，将目标SVM解释为一个惩罚+正则项)**

软间隔支持向量机可以解释为牺牲某些点上必须百分百划分正确的限制，以此来换取更大的分隔超平面，而牺牲某些点分类的准确性 ，就需要添加一个惩罚项。因此可以解释为软间隔支持向量机是在支持支持向量机的基础上添加了松弛变量引入的惩罚因子加上正则化项的SVM。

**2，解释随机梯度下降算法的原理。使用随机梯度下降法(而不是梯度下降法)的好处是什么?**

梯度下降（GD）是最小化风险函数、损失函数的一种常用方法，随机梯度下降是一种迭代思路，对比于批梯度下降，随机梯度下降是通过随机选取一组样本迭代更新一次。随机梯度下降仅以当前样本点进行最小值求解，通常无法达到真正局部最优解，但可以比较接近。

相比于普通的梯度下降以及批梯度下降的好处：

每轮迭代中，随机优化某一条训练数据上的损失函数，每一轮的参数的更新速度会大大加快，模型收敛速度也会大大加快。

**3，过度拟合是什么?如何防止过度拟合(在传统方法和深度学习中)?**

答:过拟合是指模型再训练过程中表现的异常之好，但是在测试的时候表现的特别差，过拟合意味着训练误差很低，测试误差很高，也就是低偏差，高方差。

防止过拟合的方法在传统机器学习中，

- 重新分析，清洗数据
- 添加数据，减少特征
- 加入正则化，降低模型复杂度
- 集成学习(bagging/bossting)

防止过拟合的方法在深度学习中:

- dropout(随机失活)，正则化
- 添加数据
- 根据误差分析结果修改输入特征大小
- 降低模型复杂度(每层神经元个数/神经网络层数)
- 提前终止

**4，解释什么是RNN中的梯度消失爆炸问题?(我们需要潜在的数学原因)考虑图像字幕问题。**

答：梯度消失，梯度爆炸问题本质上是由于随着深度的加深，受到权重信息，激活函数的影响，连乘机制所引发的一系列问题。

简单来说：在用反向传播算法计算误差项时每一层都需要乘以本层激活函数的导数:
$$
\delta^{(l)} = (W^{(l+1)})^T\delta^{(l+1)}\bigodot f'(u^{(l)})
$$
如果激活函数的导数的绝对值小于1，多次连乘之后误差项很快会衰减到接近于0，参数的梯度值由误差项计算得到，从而导致前面层的权重梯度接近于0，参数无法得到有效更新，便是梯度消失问题。如果激活函数导数的绝对值大于1，多次乘积之后权重值会趋向于非常大的值，从而导致梯度爆炸问题。



**5，给定一个图片作为输入，你的算法应该输出一个描述图片的句子。**

**(a)描述一个可以做到这一点的神经网络结构。(如果你使用众所周知的CNN或RNN结构，你不需要深入细节。只需说明如何使用它们(什么是输入，什么是输出)。**

此任务其实就是图像理解任务，是一种动态的目标检测任务，根据全局信息生成图像摘要，可以用RNN替换CNN来编码图像，从翻译角度看，原文字就是图像，目标文字就是生成的描述，通过预训练的InceptionNet提取图像特征，然后将softmax前一层数据作为图像编码后的特征，传入网络中(LSTM),然后为了输入匹配，图像特征V还要乘以一个Wi，从而在维度上等于We*S。同样，图中在P1-Pn的位置少了一个输出变换矩阵Wo，要将中间变量转换成目标文字。

**(b)描述训练过程(训练数据是什么?目标是什么?)**

通过卷积抽取图像特征，加入LSTM通过图像多标签分类图区出图像中可能存在的属性，这些属性则是根据字典中出现频率最高的一些单词所组成的。

目标最小化损失函数，跟多标签属性，相对比，便是文本相似度匹配的问题。

**(c)描述测试过程(在测试阶段，给出一个图片作为输入，你的算法如何输出一个描述图片的句子)**

抽取出图像特征后，训练完成，通过LSTM或者其他的NLP网络实现文本生成。

**(d)假设我们想要有一个参数来确定输出句子的多样性(在一个极端,输出几乎是一个确定性的句子,和另一个极端,输出几乎是一个随机序列)可以通过添加一个参数将softmax函数。你会怎么做?(合理的答案可能不止一个。)**

不好意思，图像方面了解的不多，这个暂时想不出来。




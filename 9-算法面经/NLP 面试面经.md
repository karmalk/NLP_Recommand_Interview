# NLP 面试面经

1. 基础的数据结构：插入排序、选择排序 （记下时间复杂度）， 链表新增、删除，二叉树的遍历，其他场景算法题大多出自leetcode
2. 逻辑回归损失是什么， 手动推导一遍
3. 对集成学习， SVM的理解，以公式的形式写出来最好
4. 对HMM ，CRF的理解， CRF的损失函数什么，维特比算法的过程
5. 手写一个tfids
6. word2vec的CBOW与SkipGram模型及两种训练方式(负采样\层级softmax)， 两种训练方式的区别和应用场景,
  7.word2vec和fasttext的区别， 训练word2vec的有哪些重要参数
7. LSTM的单元结构图和6个公式要记住
8. 有几种Attention, Attention和self-Attention是具体怎么实现的，对应什么场景
9. BERT的模型架构，多少层，什么任务适合bert，什么任务不适合，应用在你写的项目改怎么做
10. tensorflow手写一个卷积代码， BILSTM + CRF模型的原理，记住常用基础api(比如jieba添加默认词典api，分词api)
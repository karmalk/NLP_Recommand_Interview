# 聚类算法

聚类属于无监督学习问题，其目标是将样本集划分为多个类，保证同一类的样本之间尽量相似，不同类的样本之间尽量不同，这些类成为**簇**，聚类算法没有训练过程，直接完成对一组样本的划分。

聚类也算是一种分类问题，它的目标是确定每个样本所属的类别，但这里的类别并非制定好的，由算法确定。

## 1.都有哪些聚类算法，说一下你最熟悉的一种聚类算法

聚类本质上是集合划分的问题，要解决的核心问题是如何**定义簇**，通常的做法是根据簇内样本间的距离，样本点在数据空间中的密度确定。对簇的不同定义导致了各种不同的聚类算法，常见的聚类算法有以下几种：

- **连通性聚类**：代表为层次聚类算法，根据样本间的连通性(距离)来构造簇，所有联通的样本属于同一个簇。
- **基于质心的聚类**：代表为K-means算法，它用中心向量来表示一个簇，样本所属簇由它到每个簇的中心向量的距离确定。
- **基于概率分布的聚类**：这种算法假设每种类型的样本服从某一种概率分布，如多维正态分布，代表为**EM算法**，**高斯混合模型**
- **基于密度的聚类**：**DBSCAN算法**，**OPTICS算法**和**均值漂移(Mean shift)**,将簇定义为空间中样本密集的区域。
- **基于图的算法**:这类算法用样本点构造出带权重的无向图，每个样本是图中的一个顶点，然后使用图论中的方法完成聚类。典型算法为**谱聚类**

## 2.介绍一下K-means聚类算法

K均值算法是一种无监督的聚类算法，算法将每个样本分配到离他最近的那个类中心所代表的类，而类中心的确定又依赖于样本的分配方案。在实现时，先随机初始化每个类的类中心，然后计算样本与每个类的中心的距离，将其分配到最近的那个类，然后根据这种分配方案重新计算每个类的中心。这也是一种分界点优化的策略。

与KNN算法一样，这里也依赖于样本之间的距离，因此需要定义距离的计算方式，最常用的是欧式距离，也可以采用其他距离定义，算法在实现时要考虑下面几个问题：

- **类中心向量的初始化**：一般采用随机初始化。最简单的是Forgy算法，它从样本集中随机选择K个样本作为初始类中心。第二种方案时随机划分，它将所有样本随机分配给K个类中的一个，然后按这种分配方案计算各个类的类中心向量。
- **参数K的设定**；可以根据先验知识人工指定一个值，或者由算法自己确定
- **迭代终止的判定规则**。一般做法是计算本次迭代后的类中心和上一次迭代时的类中心之间的距离，如果小于指定阈值，则算法终止。


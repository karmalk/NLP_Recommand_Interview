## 提前批 NLP 凉经

tags: 博客文章

---

## OPPO 提前批

### 一面

等了将近4个小时，Oppo的效率有点差呀。

- 项目
- Transformer 结构， 大致说一下
- 懂 ELMO 吗？ 谈谈 ELMO 的结构
- 数据处理的一些手段
- **BertTextClassification** 都做了啥
- 语言模型懂得多么？ 简单谈谈
- Word2Vec 的 Nagative sample 
- Bert 没有很深入，简单谈谈
- 你一般怎么找论文（然后我就说我看论文蛮快的）
- 一道编程题： [743, 74  2, 54], 组成最大的数为 74743542
- 你有什么想问我的吗？

### 二面 - 总监/部长面

面我的年纪应该不小了，应该是不太懂技术的，感觉不太看得起深度学习。

- 评价一下你的一面面试官（我说，面试官好像没有跟进最新paper，其实可以聊一下， 不过面试官真的很nice）
- 你的一面面试官是做翻译的，我看你好像偏向搜索，所以谈谈你想做啥？（我就说我想做搜索方面的）
- 简单聊了一下Github项目，和阅读理解。
- 你有什么想问我的吗？ 然后我问了俩问题。

然后， 凉凉。

### 为啥凉 - 自我分析(安慰)一波

- 岗位少： 我投的方向只招收5个人，还是机器翻译 + 对话两个方向总共招这么点人。 说实话，感觉 Oppo对NLP并不看重， 对比 CV 就能看的出来。
- 竞争激烈，神仙打架

## 今日头条凉经

### 1.  一面

- 先自我介绍一下，主要说自己的研究方向（阅读理解，balabala）

- 深挖了一下 Bert 的细节（包括预训练过程细节，损失函数与自己使用的一些经验，在阅读理解与分类问题上)

- 语言模型相关： AR , AE 模型（我自己扩展的，面试官没打断）

- 我们来一道有意思的概率题（瞬间心里咯噔一下，概率论早就还给老师了，答的并不好，难受）

  ```
  一个地区的某个疾病的患病率为 0.01， 一个模型能够预测患病与否，错误率为 0.01， 现在，我已经被检测出来患病了， 求我真正患病的概率。
  ```

  假设真正患病为事件A， 预测为患病为事件B， 那么我们要求：
  $$
  P(A|B) = \frac{P(AB)}{P(B)} = \frac{P(B|A) * P(A)}{P(B)} = ?  \qquad \text{俺就答到这，不会算了}
  $$

- 我们来一道有意思的编程题：

  ```
  将驼峰命名方式为 abcdAutoDecoder， abcHTTPDecoder 改为下划线命名为 abcd_auto_decoder, abc_http_decoder
  ```

  一道贪心的题， 比较简单。

- 又问了一些 Pytorch 的内容，我觉得主要看我对 Pytorch 熟不熟悉

- 你可以问我一些问题， 然后我就问了俩问题， 就道谢离开。

### 2. 原因分析

概率论那道题没有答上来，算法写的不是很好，虽然答出来了，但因为题很简单，边界处理的不干净。

## 提前批 - 阿里大文娱

### 1. 一面

- 简单介绍一下自己
- 项目从头到尾问了问
- 目前主要做什么？
- Bert
- Transformer
- 一道概率题，54张牌，分为三份，每份18张，求大小王在一起的概率
- 写了一道快排

### 2. 二面

- 介绍一下自己
- 项目谈了谈
- 做过 文本聚类 方面的工作吗
- 会C++吗
- 会其余一些任务吗，如命名实体识别
- 来一到编程题。 **给一句话，求里面长度最长的单词**。（写的很快，但有小bug，面试官很不满意）

### 自我分析

凉的原因在于： 

- c++ ， 很多靠这个卡人的
- 编程题边界没处理干净

## 学霸批 - 拼多多

### 1. 一面 - hr

- 加班能接受吗？ 11， 11， 6
- 父母都是做什么的？
- 手里的offer 情况，没有去试试头条吗？
- 如果手里有百度和拼多多的offer， 你选哪个？
- 你有什么想问我的吗？

### 2. 二面

- 聊一聊项目和Bert 
- 一道概率题（忘记是啥了）
- 一道编程题： 长度为 n-1 的数组中，数字全部都是 1-n 的数，找出那个没有出现的数（当时智障了，居然答的乱七八糟）

### 三面

- Word2Vec  的Skip-Gram模型
- 多头注意力机制
- 两道编程题：
  - 求一棵二叉树的深度
  - 给定一个二维数组， 数组中全是 0 和 1， 求孤岛中所有为 1 的坐标（当时没有现在强，没做出来，面试官急着吃饭）

### 自我分析

我个人觉得还是编程题部分没有答好，因为题蛮简单的，答成这样的确有挂的风险。 此外，我看到接到offer 的人，很多手上都握着bat，头条至少一家的offer， 感觉十月份会有很多拒的人。

## 网易- 提前批

### 1. 一面

- 自我介绍， 这部分感觉最重要
- 编程题：编辑距离
- 编程题：一道链表medium，忘了
- 聊了 linux命令， git命令， 正则
- BERT 简单聊了聊

### 二面

- 自我介绍，聊项目
- 聊语言模型， Bert， XLNet等，我吹了一波
- 然后聊了聊linux， 给正则匹配

### 总监面

- 自我介绍
- 总监说，技术方面我不问，我们谈谈落地， 博客写的不错（这个应该加分很大）
- 我们有道目前布局 AI 教育方面，你是做阅读理解的，你觉得阅读理解能用在我们哪些产品上？ 就这个问题，一直深挖，谈了将近50分钟。

### HR面 - 15分钟

面试官本来以为是现场面，hr这边通知我是 视频面，因此前面很多时间都浪费了，所以只面了15分钟。

我态度很好，面试官觉得很加分。

- 自我介绍一下
- 你选择工作主要看哪些方面：我说先看团队，再看方向，然后看地点， 工资什么的对我不重要。 最后舔了一波： 如果网易这边要我的话，我就结束秋招了， 面试官听了很开心
- 你觉得你在别人眼中是什么样子： 我就说我算是技术比较强的一波人，大家有问题都会向我寻求帮助，获得“大神”称号
- 你觉得你是一个怎么样的人？ 我是一个很开朗的人，很喜欢分享，您看我的博客就知道了，在团队中往往起到一个活跃气氛的作用。
- 你有什么问题想问我的吗？

## 360 - 垃圾

估计我投的岗不招人

### 一面 - 10分钟

聊了聊项目，谈了谈我的几个仓库都在做啥，就过了。  excuse me？？？

### 二面 - 10分钟

项目简单说一下，说了一下他们这边在做什么， 然后问你有没有什么问题， 就凉了。 （没有问技术） excuse me？ 不招人就直说， 浪费我时间。

## 小米

### 一面

- 自我介绍
- 聊项目
- 聊 Transformer， 包括各个细节， 功能，并用 pytorch 写了一下多头
- Layer Normalization 原理，用 pytorch 写一下
- 一道编程题： 编辑距离

### 二面

面试官情商不高，态度优点居高临下， 让我很不舒服。

- softmax 公式， 会溢出吗？ 怎么解决溢出？ 
- Word2Vec 的多层softmax 是怎么实现的，思路是怎样的，损失函数变化
- 阅读理解应用？ 做过问答系统吗？
- 机器翻译了解吗？
- 你的博客对我来说一点用都没，我写的一定比你好... 

技术问题就完了，直言我做的不够深。 然后问我，你有什么想问的吗？

我个人觉得这是很恶心的一点， 因为我是做阅读理解的，你又没问，怎么知道我做的不深？ 还说我数据结构不扎实， 我编辑距离都写出来了，就因为 word2vec 的多层softmax 没有联想到哈夫曼树，就说我不深？

- 反问： 您觉得我有哪些方面不足？ 面试官说了一堆，什么这个不行，那个不行
- 反问：  在阅读理解领域，您觉得什么叫深？ 面试官说，我不是做这个的，我不知道， excuse me？

## 搜狗

### 1. 一面

- 自我介绍，项目
- 现在还在搜狗实习吗？
- 一道概率题： 对于一个超长文本，等概率的从该文本中抽取 m 行
- 一道编程题： 编辑距离

### 2. 二面

- 自我介绍
- 聊 Bert 细节
- 聊 Transformer 细节，用 pytorch 写了下多头和 layernormlization
- 编程题：判定二叉树为对称二叉树，很简单
- 会c++吗？

如果挂了，必然是挂在 c++ 上了， 等通知。

## 猿辅导

做题就对了， 一面一道medium， 一道hard。 二面一道hard
















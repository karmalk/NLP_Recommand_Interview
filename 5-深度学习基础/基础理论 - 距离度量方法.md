# 距离度量方法

tags: 机器学习

---

## 1. 欧式距离

衡量点之间的直线距离
$$
二 维： d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2} \\
n 维： d = \sqrt{(x_1 - y_1)^2 + ... + (x_n - y_n)^2}
$$

## 2. 曼哈顿距离

$$
二 维： d = |x_1 - x_2| + |y_1 - y_2| \\
n 维：d = |x_1 - y_1| + ... + |x_n - y_n|
$$

## 3. 余弦距离

将两个点看做是空间中的两个向量，通过衡量两向量之间的相似性来衡量样本之间的相似性。
$$
二维：cos \, \theta = \frac{x_1 * x_2 + y_1 * y_2}{\sqrt{(x_1^2 + y_1^2)} * \sqrt{x_2^2 + y_2^2}} \quad 或 \quad cos \, \theta = \frac{a * b}{|a| * |b|} \\
n 维： cos \, \theta = \frac{x_1 * y_1 + ... + x_n * y_n}{\sqrt{x_1^2 + ... + x_n^2} * \sqrt{y_1^2 + ... + y_n^2}}
$$

## 4. 切比雪夫距离

各对应坐标数值差的最大值。
$$
二维： d = max(|x_1 - x_2|, |y_1 - y_2|) \\
n 维： d = max(|x_1 - y_1|, ... ,|x_n - y_n|)
$$

---

## QA

### 1. 余弦相似度 与 欧式距离的区别与联系

- 区别：

  欧式距离和余弦相似度都能度量2个向量之间的相似度，但是欧式距离从2点之间的距离去考量，余弦相似从2个向量之间的夹角去考量。举例如下：

  > 假设 2人对三部电影的评分分别是 `A = [3, 3, 3]` 和 `B = [5, 5, 5]`
  >
  > 那么2人的欧式距离是 根号12 = 3.46， A、B的余弦相似度是1（方向完全一致）。

  从上例可以发出，2人对三部电影的评价趋势是一致的，但是欧式距离并不能反映出这一点，余弦相似则能够很好地反应。余弦相似可以很好地规避指标刻度的差异，最常见的应用是计算 **文本的相似度** 。

- 联系：

  **归一化后计算的欧式距离是关于余弦相似的单调函数**，可以认为归一化后，余弦相似与欧式距离效果是一致的（欧式距离越小等价于余弦相似度越大）。

  因此可以将 **求余弦相似转为求欧式距离** ，余弦相似的计算复杂度过高，转为求欧式距离后，可以借助`KDTree`（KNN算法用到）或者`BallTree`（对高维向量友好）来降低复杂度。

![1.cosine](..\img\1.cosine.png)


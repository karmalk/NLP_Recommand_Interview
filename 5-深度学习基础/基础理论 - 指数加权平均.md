# 指数加权平均

tags: 深度学习

---

## 原理

**指数加权平均本质上是一种近似求取平均值的方法。**
$$
V_t = \beta V_{t-1} + (1-\beta)\theta_t 
$$
我们也以吴恩达课上的例子举例， 假设

- $V_t$  表示从第0天到第 $t$ 天的平均温度值。
- $\theta_t$ 表示第 t 点的温度值。

我们具体展开来说， 假设时间  $t = 100$ ，加权参数 $\beta = 0.9$ ， 那么则有：
$$
V_{100} = 0.9V_{99} + 0.1\theta_{100}  \\ V_{99} = 0.9V_{98} + 0.1\theta_{99}   \\ V_{98} = 0.9V_{97} + 0.1\theta_{98}
$$
我们将上式带入化简有：
$$
V_{100} = 0.1 \theta_{100} + 0.1 * 0.9  \theta_{99} + 0.1 * 0.9^2 \theta_{98} + \cdots + 0.1 * 0.9^{99}  \theta_1 + 0.1 * 0.9^{100}\theta
$$
观察上式我们发现， 指数加权平均实质上就是**以指数式加权递减的移动平均。 各数值的加权而随时间而指数式递减，越近期的数据加权越重，但较旧的数据也给予一定的加权。**

但有一点需要注意的是， 我们观察上式，在最后一项中它的系数为 $0.99^{100}$ , 这个数已经很接近于0了， 这就意味着，在 $t = 0$ 时刻对加权平均值所起到的作用微乎其微， 继而引出一个问题： **我们加权平均所得到的值到底平均了多少天？** 

答案是 $\frac{1}{1-\beta}$  天。这是因为当 $\beta = 0.9$ 时， 有 $0.9^{10} = 0.3486...$ ， 当 $\beta = 0.8$  时， 有 $0.8^5  = 0.3276...$ ， 也就是说当权重下降到 $\frac{1}{3}$（或者说$\frac{1}{e}$） 以下时就被忽略不计了。

前面说到指数平均的本质依旧是**计算平均值**，那么在深度学习中为什么不使用我们常用的平均值求法，而要搞得这么复杂呢？ 答案是**效率以及内存问题。**

在深度学习中，数据量经常是非常庞大的， 如果我们使用传统方法来计算平均值，无论是从内存还是从计算量上， 对计算机的压力是很大的， 而对比对数加权平均方法， 我们每次只需要保存上一时刻的值，无论是内存开销还是计算量都小的可怜。 

## 偏差修正

当我们还有指数加权平均来计算平均值时， 一开始的指数加权平均值会很小， 不能代表平均值， 所以需要使用偏差修正：
$$
V_t = \frac{V_t}{1 - \beta^t} 
$$
但是一般机器学习并不关心一开始的指数加权平均值，所以可以不用偏差修正来修正。


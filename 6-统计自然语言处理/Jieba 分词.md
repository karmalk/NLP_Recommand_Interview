# Jieba 分词

**基于核心思想和分为两大类**

- 基于词典的分词，按照词典切分成词，再寻找词的最佳组合方式
- 基于字的分词，由字构成词，句子分成一个个的字，再将字组合成词，寻找最优策略。

现有的分词算法可分为三大类

- **基于字符串匹配的分词方法**
  - 也叫机械分词方法，按照一定策略将待分析的汉字串与一个“充分大的”机器词典中的词条进行匹配，若在词典中找到某个字符串，则匹配成功
  - 正向最大匹配法 (由左到右的方向)
  - 逆向最大匹配法 (由右到左的方向)
  - 最少切分 (使每一句中切出的词数最小)
  - 双向最大匹配法(从左到右，从右到左依次扫描)
- **基于理解的分词方法**
  - 这种分词方法使通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法，语义分析，利用句法信息和语义信息来处理歧义现象，它通常包括三个部分：分词子系统，句法语义子系统，总控系统。在总控系统协调下，分词子系统可以获得有关词，句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。由于汉语言知识的笼统，复杂性，难以将各种语言信息组织成机器可直接读取的形式，因此，目前基于理解的分词系统还处在试验阶段。
- **基于统计的分词方法**
  - 给出大量已经分词的文本，利用统计机器学习模型学习词语切分的规律，从而实现对未知文本的切分。例如最大概率分词方法和最大熵分词方法等。随着大规模语料库的建立，统计机器学习方法的研究和发展，基于统计的中文分词方法逐渐成为主流
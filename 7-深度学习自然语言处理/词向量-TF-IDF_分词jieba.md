## TF-IDF和textrank,说下公式



### TF-IDF (词频-逆文档频率)

TF-IDF 是信息检索领域中搜索词的重要性度量；用于衡量一个关键词w对于查询所能提供的信息，

**TF(词频)**表示关键词w在文档Di中出现的频率
$$
TF_{w,D_{i}} = \frac{count(w)}{|D_{i}|}
$$
count(w)为关键词w的出现次数

|Di|为文档Di中所有词的数量。

**IDF(逆文档频率)**反映关键词的**普遍程度**，当一个词越普遍(即有大量文档包含这个词)时，其IDF越低，反之IDF值越高
$$
IDF_{w} = log\frac{N}{\sum_{i=1}^{N}T(w,D_{i})}
$$
N:所有文档总数

T(w,Di)表示文档Di是否包含关键词，若包含则为1,否则为0,若词w在所有文档中均未出现，则IDF公式中的分母为0；因此需要对IDF做平滑

关键词w在文档Di中的TF-IDF的值
$$
TF-IDF_{w,D_{i}} = TF_{w,D_{i}}*IDF_{w}
$$
总结:

- **当一个词在文档频率越高并且新鲜度高(普遍都底),则TF-IDF值越高**
- **TF-IDF兼顾词频和新鲜度，过滤一些常见的词，保留能提供更多信息的重要词**

### TextRank(候选词，摘要，短语提取)

通过词之间的相邻关系构建网络，然后用PageRank迭代计算每个节点的rank值，排序rank值即可得到关键词，PageRank本来时用来解决网页排名的问题，网页之间的链接关系即为图的边，迭代计算公式
$$
PD(V_{i})=(1-d)+d*\sum_{j\in{I_{n}(V_{i})}}\frac{1}{|Out(V_{j})|}PR(V_{j})
$$

- PR(Vi)表示节点Vi的rank值
- In(Vi)表示结点Vi的前驱结点集合
- Out(Vj)表示结点Vj的后继结点集合
- d用于做平滑

TextRank将某一个词与之前的N个词，以及后面的N个词均具有图相邻关系(N-gram语法模型)

具体实现，设置一个长度为N的滑动窗口，所有在这个窗口之内的词都视作词结点的相邻结点;则TextRank构建的词图为无向图

考虑到不同词对可能有不同的共线，TextRank将共现作为无向图边的权值，迭代公式如下
$$
WS(V_{i})=(1-d)+d*\sum_{j\in{In(V_{i})}}\frac{w_{ji}}{\sum_{V_{k}\in{Out(V_{j})}}w_{jk}}WS(V_{j})
$$
Wji 用来表示两个节点之间的边链接有不同的重要程度

## jieba分词原理，提高分词准确率

**基于核心思想和分为两大类**

-  基于词典的分词，按照词典切分成词，再寻找词的最佳组合方式
- 基于字的分词，由字构成词，句子分成一个个的字，再将字组合成词，寻找最优策略。

现有的分词算法可分为三大类

- **基于字符串匹配的分词方法**
  - 也叫机械分词方法，按照一定策略将待分析的汉字串与一个“充分大的”机器词典中的词条进行匹配，若在词典中找到某个字符串，则匹配成功
  - 正向最大匹配法 (由左到右的方向)
  - 逆向最大匹配法 (由右到左的方向)
  - 最少切分 (使每一句中切出的词数最小)
  - 双向最大匹配法(从左到右，从右到左依次扫描)

- **基于理解的分词方法**
  - 这种分词方法使通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法，语义分析，利用句法信息和语义信息来处理歧义现象，它通常包括三个部分：分词子系统，句法语义子系统，总控系统。在总控系统协调下，分词子系统可以获得有关词，句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。由于汉语言知识的笼统，复杂性，难以将各种语言信息组织成机器可直接读取的形式，因此，目前基于理解的分词系统还处在试验阶段。
- **基于统计的分词方法**
  - 给出大量已经分词的文本，利用统计机器学习模型学习词语切分的规律，从而实现对未知文本的切分。例如最大概率分词方法和最大熵分词方法等。随着大规模语料库的建立，统计机器学习方法的研究和发展，基于统计的中文分词方法逐渐成为主流。